# -*- coding: utf-8 -*-
"""Clasification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z_BCVstUdwv4bkAcZMo23b_9w5tXL6RQ
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from scipy.stats import entropy
import random
import seaborn as sns
import time

# %matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.axes_grid1 import make_axes_locatable
from ipywidgets import interact

from sklearn.model_selection import StratifiedKFold  # Add this line


from sklearn import linear_model
from sklearn.manifold import TSNE
from sklearn.linear_model import ElasticNet
from sklearn.svm import LinearSVC
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.feature_selection import VarianceThreshold, SelectFdr, f_classif, SelectFromModel
from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split
from sklearn.metrics import accuracy_score, classification_report
#from sklearn.metrics import accuracy_score, precision_recall_curve, f1_score, auc, roc_curve, roc_auc_score, precision_score, log_loss, recall_score

# Clean data set Test
# Read data
path='/content/drive/MyDrive/Sorbonne/MEETU/molzip_bren/ene29/'


import gzip
data_5000 = pd.read_csv(path+"pilot_library.csv")

data=[]
pocket_atp = "EFSSNVANYQKVGMQKYSTLQGPPGTGKSHFAIGLALYYPSARIVYTACSHAAVDALCEKALKYLPIDKCSRIIPARARVECFDKFKVNSTLEQYVFCTVNALPETTADIVVFDEISMATNYDLSVVNARLRAKHYVYIGDPAQLPAPRTLLTKGTLEPEYFNSVCRLMKTIGPDMFLGTCRRCPAEIVDTVSALVYDNKLKAHKDKSAQCFKMFYKGVITHDVSSAINRPQIGVVREFLTRNPAWRKAVFISPYNSQNAVASKILGLPTQTVDSSQGSEYDYVIFTQTTETAHSCNVNRFNVAITRAK"
liste_complexe_kd_len_zip = []
for ligand in data_5000["smiles"]:
    data.append([ligand+pocket_atp,len(gzip.compress((ligand+pocket_atp).encode()))])
new_df=pd.DataFrame(data,columns=["seq","len_zip"])
new_df["eos"]=data_5000["eos"]
new_df.to_csv(path+"test_atp.csv")

data=[]
pocket_arn = "KATEETFKLSYGIATVREVLSDRELHLSWEVGKPRPPLNRNYVFTGYRVTKNSKVQIGEYTFEKGDYGDAVVYRGTTTYKLNVGDYFVLTSHTVMPLSAPTLVPQEHYVRITGLYPTLNISDEFSSNVANYQKVGMQKYSTLQGPPGTGKSHFAIGLALYYPSARIVYTACSHAAVDALCEKALKYLPIDKCSRIIPARARVECFDKFKVNSTLEQYVFCTVNALPETTADIVVFDEISMATNYDLSVVNAR"
liste_complexe_kd_len_zip = []
for ligand in data_5000["smiles"]:
    data.append([ligand+pocket_arn,len(gzip.compress((ligand+pocket_arn).encode()))])
new_df=pd.DataFrame(data,columns=["seq","len_zip"])
new_df["eos"]=data_5000["eos"]
new_df.to_csv(path+"test_arn.csv")

!pip install indexed-gzip
import gzip

def cross_val(data_clean,labels,label_name,clusters):
    """ Make cross_validation with many model to plot score and return the time of execution of each model
    data_clean : dataframe with feature and no missing value
    labels : list of label
    label_name : name of the target label (str)
    clusters : number of class
    cv : number of cross validation
    """
    index = ["RandomForest"]
    liste_temps = []
    liste_scores = []
    cv=10

    # RandomForest
    rf = RandomForestClassifier()

    # plot
    plt.figure(figsize =(8, 5),facecolor="white")
    plt.boxplot(liste_scores,labels=index)
    plt.title("Cross validation score with different classifer (target: %s)"%(label_name))
    plt.show()

    return liste_temps

def clean_data(df_ini,label_p,path,clusters):
    """ Pre-processing of df
    df : dataframe of features
    label_c : used label to make classification
    """

    # 1 Choose
    df=df_ini[['len_zip', 'kd/ki', 'value']]


    # 2 Categorization of str
    non_cat=list(df.columns)
    dic_cat = {}
    df1 = df
    for feat in df1:
        if (df1[feat]).dtype == "object":
            non_cat.remove(feat)
            df1[feat] = df[feat].astype('category')
            dic_cat[feat] = dict(enumerate(df[feat].cat.categories))
            df1[feat] = df[feat].cat.codes

    # Pour Continuous
    if label_p=="kd/ki":
      if clusters==2:
          bins=[0,600,999999999]
          labels=['0','1']
      elif clusters==3:
          bins=[0,500,900,999999999]
          labels=['0','1','2']
      elif clusters==4:
          bins=[0,20,500,900,999999999]
          labels=['0','1','2','3']
      df1[label_p] = pd.cut(df[label_p], bins=bins, labels=labels)
      df1.to_csv(path+"class_kd.csv")
    elif label_p=="value":
      if clusters==2:
          bins=[0,14,16]
          labels=['1','0']
      elif clusters==3:
          bins=[0,2,10,16]
          labels=['2','1','0']
      elif clusters==4:
          bins=[0,3,5,7,16]
          labels=['3','2','1','0']
      df1[label_p] = pd.cut(df[label_p], bins=bins, labels=labels)
      df1.to_csv(path+"class_values.csv")

    return df1

def metrics_df(X_train,y_train,X_test,label_name,ci,clusters):
    """ Return some metrics of different model in a dataframe
    data_clean : dataframe with feature and no missing value
    labels : list of label
    label_name : name of the target label (str)
    clusters : number of class
    cv : number of cross validation
    """
    index = ["RandomForest","AdaBoost","KNeighbors","GradientBoosting","SVM"]
    liste_score = []
    liste_precision = []
    liste_recall = []
    liste_F1 = []
    liste_support = []

    cv=10

    #Data
    #X_train, y_train,  X_test, y_test = train_test_split(data_clean, labels, test_size=0.2, random_state=42)

    #                         Supervised model
    # RandomForest
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    #y_pred = rf.predict(X_test)

    # AdaBoost
    ab = AdaBoostClassifier(n_estimators=100, algorithm="SAMME", random_state=0)
    ab.fit(X_train, y_train)
    #y_pred = ab.predict(X_test)

    # KNeighbors
    neigh = KNeighborsClassifier(n_neighbors=clusters)
    neigh.fit(X_train, y_train)
    #y_pred = neigh.predict(X_test)

    # GradientBoosting
    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)
    gbc.fit(X_train, y_train)
    y_pred = gbc.predict(X_test)

    # SVM
    svm = LinearSVC(C=10, penalty="l1", dual=False,max_iter=10000)
    svm.fit(X_train, y_train)
    #y_pred = svm.predict(X_test)

    liste_model = [rf,ab,neigh,gbc,svm]





    for model in liste_model :
        # Ensure unique classes in labels
        unique_classes = np.unique(y_train)

        # Use StratifiedKFold to ensure that each fold has the same distribution of classes
        cv_iterator = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
        pred = cross_val_predict(model, X_train, labels, cv=cv_iterator)

        liste_score.append(accuracy_score(y_train, pred))

        classification_rep = classification_report(y_train, pred, output_dict=True)

        # Access specific values for a particular class (e.g., class_1)
        precision_class_1 = classification_rep[ci]['precision']
        recall_class_1 = classification_rep[ci]['recall']
        f1_score_class_1 = classification_rep[ci]['f1-score']
        support_class_1 = classification_rep[ci]['support']

        liste_precision.append(precision_class_1)
        liste_recall.append(recall_class_1)
        liste_F1.append(f1_score_class_1)
        liste_support.append(support_class_1)

    df = pd.DataFrame({'Accuracy Score': liste_score, 'Classification': liste_precision,'Recall':liste_recall,'F1-score for class':liste_F1,'Support for class:':liste_support}, index=index)

    return df,y_pred

# Read data
path='/content/drive/MyDrive/Sorbonne/MEETU/molzip_bren/ene29/'
df_ini= pd.read_csv(path+"data_PDB_Kd-2.csv")

# Parameters:
targets=["kd/ki","value"]
label_p="kd/ki"

#label_p="value"

""" Clean the dataset, plot and print metrics
df_ini : starting dataset
label_p : name of label that we predict
targets : list of target
"""

clusters=4

# 1. Clean data
datos=clean_data(df_ini,label_p,path,clusters)
labels=datos[label_p]
df=datos.drop(columns=targets) # Columns to delete

test_data= pd.read_csv(path+"test_atp.csv")
X_test=test_data.drop(columns=["seq","Unnamed: 0","eos"])
print(X_test)

# 3 Test & Calculate accurac
ci='0'
df_metric,y_pred = metrics_df(df,labels,X_test,label_p,ci,clusters)
test_data["y"]=y_pred
display(df_metric)

# Plot
df_metric = df_metric.style.bar(subset=['Accuracy Score'], color='#f54eb2')
df_metric = df_metric.bar(subset=['Precision'], color='#83c2fc')
df_metric = df_metric.bar(subset=['Recall'], color='#c796f2')

# Get best ligands
test_data[test_data["y"]=='0']